{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CJDqQbKIfxp"
   },
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 231 Machine Learning: Home Assignment 5 -- Clustering** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: K-means (Yuchong), GMM (Divya), EM (Divya)**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Yuchong, Divya** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 29th May** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: Name, Personal No., Email** <br />\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "General guidelines:\n",
    "*   All solutions to theoretical and pratical problems must be submitted in this ipynb notebook, and equations wherever required, should be formatted using LaTeX math-mode.\n",
    "*   All discussion regarding practical problems, along with solutions and plots should be specified in this notebook. All plots/results should be visible such that the notebook do not have to be run. But the code in the notebook should reproduce the plots/results if we choose to do so.\n",
    "*   Your name, personal number and email address should be specified above.\n",
    "*   All tables and other additional information should be included in this notebook.\n",
    "*   **All the answers for theoretical questions must be filled in the cells created for you with \"Your answer here\" below each question, but feel free to add more cells if needed.**\n",
    "*   Before submitting, make sure that your code can run on another computer. That all plots can show on another computer including all your writing. It is good to check if your code can run here: https://colab.research.google.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2SZprryJ3Yn"
   },
   "source": [
    "# Practical problems\n",
    "\n",
    "The follwing code might be useful for this excercise.\n",
    "\n",
    "```python\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('hw5_p1a.mat')\n",
    "print (mat.keys())\n",
    "X = mat['X']\n",
    "```\n",
    "\n",
    "## [K-Means Implementation, 8 points]\n",
    "\n",
    "Q 1.1. Implement the basic (linear) $k$-means algorithm as described in the lecture, using the euclidean distance. Use (uniformly) random points from the data as initialization for the centroids. Terminate the iterative procedure when the the cluster assignments do not change. [**4 pts**]\n",
    "\n",
    "Q 1.2. Run your implementation on the matrix $X$ in **hw5_p1a.mat** with $k=2$. Each row of the matrix is an observation, and each column is a feature. Store the cluster assignment both after 2 iterations, and at convergence. Produce a scatter plot of the data with colors indicating the cluster assignments at convergence and highlight points that have changed assignment after the second iteration. [**4 pts**]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Czs7q4Y5UIUT"
   },
   "source": [
    "### Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6jdOJf_Ksf6"
   },
   "source": [
    "# GMM [4 pts]\n",
    "\n",
    "We will now consider mixture model. The probability of an observation $x \\in \\mathbb{R}^D$ is given by: $$p(x) = \\sum_{k=1}^{K} \\pi_k P(x|\\theta_k)$$ where $\\pi_k$ are the probabilities a priori and $P(x|\\theta_k)$ are multi-dimensional Gaussian characterized by their mean $\\mu_k$ and their co-variance matrix $\\Sigma_k$\n",
    ", i.e. $\\theta_k = (\\mu_k, \\Sigma_k)$.\n",
    "\n",
    "### Q 2.1.\n",
    "Plot the probability distribution $p(x)$ for D=1 , K = 2, $\\pi_1 = \\pi_2 = 0.5$ and $\\mu_1 = 1$, $\\mu_2 = 3$,$\\Sigma_1 = 1$,$ \\Sigma_2 = 10$. **[2 pts]**\n",
    "\n",
    "### Q 2.2.\n",
    "\n",
    "What is the posterior probability that an example $x=1.5$ was produced by the Gaussian $k=1$,i.e. $P(\\theta_1| x)$ ? **[2 pts]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nqn0528wUU8u"
   },
   "source": [
    "### Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gp1tmMdZKtYS"
   },
   "source": [
    "# EM algorithm for GMM [8 pts]\n",
    "\n",
    "Assume that the property prices of Gotheburg follow a mixture of 2 Gaussians, of respective parameters $(\\mu_1, \\sigma_1^2)$ and $(\\mu_2, \\sigma_2^2)$.\n",
    "\n",
    "The table below lists the prices in million SEK of some real estate transactions:\n",
    "$$\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "8& 1 & 4 & 3 & 4 & 5 & 7 & 5 & 3 & 5 \\\\ \\hline\n",
    "\\end{array}$$\n",
    "\n",
    "We will call $\\pi_1$ and $\\pi_2$ the coefficients of the two Gaussians in the mixture. Note: $\\theta^{i}$ denotes $i^{th}$ step estimate when using EM algorithm.\n",
    "\n",
    "### Q 3.1.\n",
    "\n",
    "Sort the items of the sample in ascending order and use the 5 smallest values for\n",
    "estimating $(\\mu_1, \\sigma_1^2)$ and 5 larger ones to estimate $(\\mu_2, \\sigma_2^2)$. Under these conditions, what values should logically be assigned to the weights $\\pi_1$ and $\\pi_2$? **[2 pts]**\n",
    "\n",
    "### Q 3.2.\n",
    "\n",
    "Starting from $\\theta^0 = \\{\\mu_1, \\sigma^2_1, \\pi_1, \\mu_2, \\sigma^2_2, \\pi_2\\}$ obtained from the previous question, estimate the value of responsibilities $\\gamma(z_{nk})$ according to the EM algorithm. **[3 pts]**\n",
    "\n",
    "### Q 3.3.\n",
    "Re-estimate the parameters i.e. calculate $\\theta^1$, using the current responsibilities.**[3 pts]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3.1 ###\n",
    "Values that should logically be assigned to weights $\\pi_1$ and $\\pi_2$ is 0.5. Because there are 10 data samples in total and 5 of the smallest values are used to estimate $(\\mu_1, \\sigma_1^2)$, the other 5 are used to esitmiate $(\\mu_2, \\sigma_2^2)$. It is pretty logical to assign $\\pi_1$ and $\\pi_2$ with equal value 0.5, which could be viewd as the prior probability of $z_{nk} = 1$.\n",
    "\n",
    "The code below uses the sample data to estimate $\\mu_1, \\sigma_1^2, \\mu_2, \\sigma_2^2$, which gives an estimation result of: \n",
    "$$\\mu_1 = 3, \\sigma_1^2 = 1.2 \\\\ \\mu_2 = 6, \\sigma_2^2 = 1.6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Value:\n",
      "mu_1 : 3.000000, sigma_1_square : 1.200000\n",
      "mu_2 : 6.000000, sigma_2_square : 1.600000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([8, 1, 4, 3, 4, 5, 7, 5, 3, 5], dtype=float)\n",
    "sorted_data = np.sort(data)\n",
    "\n",
    "group_1 = sorted_data[0:5]\n",
    "group_2 = sorted_data[5:10]\n",
    "\n",
    "mu_1 = np.mean(group_1)\n",
    "sigma_1 = np.var(group_1)\n",
    "\n",
    "mu_2 = np.mean(group_2)\n",
    "sigma_2 = np.var(group_2)\n",
    "\n",
    "print(\"Estimation of mean and variance:\")\n",
    "print(\"mu_1 : %f, sigma_1_square : %f\" %(mu_1, sigma_1)) \n",
    "print(\"mu_2 : %f, sigma_2_square : %f\" %(mu_2, sigma_2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3.2 ###\n",
    "The EM altorithm specifies the following formula to estimate responsibilities $\\gamma(z_{nk})$:\n",
    "$$\n",
    "\\gamma(z_{nk}) = \\frac{\\pi_k\\mathcal{N}(x_n | \\mu_k, \\sigma_k^2)}{\\sum_j\\pi_j\\mathcal{N}(x_n|\\mu_j,\\sigma_j^2)}\n",
    "$$\n",
    "We use the following code to implement this estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of responsibilities:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'guassian_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ce5a32c2af9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_responsibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mresponsibilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma(z_%d_%d): %f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-ce5a32c2af9d>\u001b[0m in \u001b[0;36mestimate_responsibility\u001b[0;34m(n, k)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mestimate_responsibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgroup_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnorm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgaussian_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguassian_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guassian_1' is not defined"
     ]
    }
   ],
   "source": [
    "pi_1 = pi_2 = 0.5\n",
    "\n",
    "class GaussianDistribution:\n",
    "    def __init__(self, mean, var):\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        \n",
    "    def get_probability(self, val):\n",
    "        n1 = np.sqrt(self.var)\n",
    "        n2 = np.sqrt(2 * np.pi * n1)\n",
    "        n3 = np.divide(1, n2)\n",
    "        n4 = np.divide(np.square(val - self.mean), 2 * self.var)\n",
    "        n5 = np.negation(n4)\n",
    "        return np.exp(n5)\n",
    "\n",
    "gaussian_1 = GaussianDistribution(mu_1, sigma_1)\n",
    "gaussian_2 = GaussianDistribution(mu_2, sigma_2)\n",
    "\n",
    "def estimate_responsibility(n, k):\n",
    "    data = group_1[n] if n <= 4 else group_2[n-5]\n",
    "    n1 = 0.5 * norm1.get_probability(data)\n",
    "    n2 = n1 + 0.5 * norm2.get_probability(data)\n",
    "    return np.divide(n1, n2)\n",
    "    \n",
    "responsibilities = np.zeros((2, 10))\n",
    "\n",
    "print(\"Estimation of responsibilities:\")\n",
    "for k in range(2):\n",
    "    for n in range(10):\n",
    "        val = estimate_responsibility(n, k)\n",
    "        responsibilities[k][n] = val\n",
    "        print(\"gamma(z_%d_%d): %f\" %(n, k, val))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LPxv3VVUabd"
   },
   "source": [
    "### Your answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hw5_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
